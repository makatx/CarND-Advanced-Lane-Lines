{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Lines Finding #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Calibrate** the camera by reading in chessboard images and locating their corners, to calculate the distortion coefficients\n",
    "- Use the distortion coefs to undistort any new images before further processing\n",
    "- Apply thresholding/gradients to get masked image of only the interesting pixels\n",
    "- **Warp** the images of the road from the car camera to get the bird's eye view of the road\n",
    "- Downsize the image 10x for the next step to work in real time\n",
    "- **Use DBSCAN** to search for lane lines' pixels by exploiting adjacency and add to collection\n",
    "- **Plot the lines using polynomial fit**\n",
    "- **Scale the poly-line** and apply to the original size warped image\n",
    "- **Overlap n subsequent images** to get better continuity and perform lane line detection \n",
    "- Record line and car position data\n",
    "- Draw on road and inverse the warp taken before to get highlighted road markings and curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statistics import mean\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from sklearn.cluster import DBSCAN\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Board ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds for colors and gradients\n",
    "thresh_x_grad = (35,255)\n",
    "thresh_S = (90,255)\n",
    "thresh_L = (90,255)\n",
    "\n",
    "# Image dimensions\n",
    "shape_x = 1280\n",
    "shape_y = 720\n",
    "\n",
    "# Scale factor\n",
    "fx = 0.10\n",
    "fy = 0.10\n",
    "\n",
    "# DBSCAN parameters\n",
    "epsilon = 25\n",
    "min_samples = 30\n",
    "invalid_centroids = 0\n",
    "\n",
    "# Perspective transform matrix and inverse matrix\n",
    "src = np.float32([(585,455), (695,455), (1100,720), (180,720)])\n",
    "dst = np.float32([(240,0), (1040,0), (1040,720), (240,720)])\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "\n",
    "\n",
    "# load distortion coefficients\n",
    "dist_pickle = pickle.load(open('dist_matrix.p', 'rb'))\n",
    "distortion = dist_pickle['dist']\n",
    "camera_mtx = dist_pickle['mtx']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lines Class ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        self.detected = False\n",
    "        self.last_fit = [np.array([False])]\n",
    "        self.all_fit = []\n",
    "        self.all_fit_ret = []\n",
    "        self.last_n_fit = []\n",
    "        self.avg_fit = None\n",
    "        self.radius_of_curvature = None\n",
    "        self.all_radii = []\n",
    "        self.last_n_r = []\n",
    "        self.last_n_x = []\n",
    "        self.avg_x = []\n",
    "        self.n = 20\n",
    "        self.r_n = 20\n",
    "        self.last_fit_weight = 7\n",
    "        self.accepted_deviation = 0.55\n",
    "        self.r_diff = 2000\n",
    "        self.all_r_ret = []\n",
    "        self.straight_line_radius = 10000\n",
    "        self.fit_diff = []\n",
    "        self.mx = 3.7/790\n",
    "        self.my = 30/720\n",
    "    \n",
    "    def set_fit(self, fit):\n",
    "        self.last_fit = fit\n",
    "        self.all_fit.append(fit)\n",
    "        if len(self.last_n_fit) < self.n:\n",
    "            self.last_n_fit.append(fit)\n",
    "        else:\n",
    "            self.last_n_fit[:-1] = self.last_n_fit[1:]\n",
    "            self.last_n_fit[-1] = fit\n",
    "    \n",
    "    def set_x(self, x):\n",
    "        if len(self.last_n_x) < self.n :\n",
    "            self.last_n_x.append(x)\n",
    "        else:\n",
    "            self.last_n_x[:-1] = self.last_n_x[1:]\n",
    "            self.last_n_x[-1] = x\n",
    "            \n",
    "    def eval_avg(self):\n",
    "        last_n_fit = np.array(self.last_n_fit)\n",
    "        last_n_x = np.array(self.last_n_x)\n",
    "        \n",
    "        weights = np.ones(last_n_fit.shape[0])\n",
    "        weights[-1] = self.last_fit_weight\n",
    "        \n",
    "        self.avg_fit = np.average(last_n_fit, axis=0, weights=weights)\n",
    "        self.avg_x = np.average(last_n_x, axis=0, weights=weights)\n",
    "    \n",
    "    def get_radius(self, fit, y=719, append=True):\n",
    "        mx= self.mx\n",
    "        my=self.my\n",
    "        \n",
    "        a = fit[0]\n",
    "        b = fit[1] \n",
    "        y = my*y\n",
    "        \n",
    "        a = mx * a /(my**2)\n",
    "        b = mx * b / (my)\n",
    "            \n",
    "        r = ((1+(2*a*y+b)**2)**1.5 ) / np.absolute(2*a) \n",
    "        self.radius_of_curvature = r\n",
    "        if append: \n",
    "            self.all_radii.append(r)\n",
    "    \n",
    "    def set_radius(self, r):\n",
    "        if len(self.last_n_r) < self.r_n :\n",
    "            self.last_n_r.append(r)\n",
    "        else:\n",
    "            self.last_n_r[:-1] = self.last_n_r[1:]\n",
    "            self.last_n_r[-1] = r    \n",
    "    \n",
    "    def validate(self, fit, x):\n",
    "        if self.avg_fit == None:\n",
    "            self.set_fit(fit)\n",
    "            self.set_x(x)\n",
    "            self.eval_avg()\n",
    "            self.all_fit_ret.append(self.avg_fit)\n",
    "            self.get_radius(self.avg_fit)\n",
    "            self.set_radius(self.radius_of_curvature)\n",
    "            self.all_r_ret.append(self.radius_of_curvature)\n",
    "            return self.avg_fit, self.avg_x\n",
    "        \n",
    "#        fit_diff = (np.abs((self.avg_fit-fit)/(self.avg_fit)))\n",
    "#        self.fit_diff.append(fit_diff)\n",
    "        self.get_radius(fit)\n",
    "        if self.radius_of_curvature > self.straight_line_radius:\n",
    "            self.set_fit(fit)\n",
    "            self.set_x(x)\n",
    "            self.eval_avg()\n",
    "            #self.radius_of_curvature = 0\n",
    "            self.all_fit.append(fit)\n",
    "            self.all_fit_ret.append(self.avg_fit)\n",
    "            self.all_r_ret.append(self.radius_of_curvature)\n",
    "            return self.avg_fit, self.avg_x\n",
    "        \n",
    "        elif np.absolute(self.radius_of_curvature - (self.last_n_r[-1])) > self.r_diff:\n",
    "            self.radius_of_curvature = np.average(self.last_n_r)\n",
    "            self.set_radius(self.radius_of_curvature)\n",
    "            self.all_fit.append(fit)\n",
    "            self.all_fit_ret.append(self.avg_fit)\n",
    "            self.all_r_ret.append(self.radius_of_curvature)\n",
    "            return self.avg_fit, self.avg_x\n",
    "        \n",
    "        else:    \n",
    "            self.set_fit(fit)\n",
    "            self.set_x(x)\n",
    "            self.eval_avg()\n",
    "            self.all_fit_ret.append(self.avg_fit)\n",
    "            #self.get_radius(self.avg_fit, append=False)\n",
    "            self.set_radius(self.radius_of_curvature)\n",
    "            self.radius_of_curvature = np.average(self.last_n_r)\n",
    "            self.all_r_ret.append(self.radius_of_curvature)\n",
    "            return self.avg_fit, self.avg_x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image overlap class ###\n",
    "(Keeping track of last n images to overlap and get better fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgOverlap():\n",
    "    def __init__(self):\n",
    "        self.n_frames = 2\n",
    "        self.last_n_img = []\n",
    "        \n",
    "    def overlap(self, img):\n",
    "        if len(self.last_n_img) == 0:\n",
    "            self.last_n_img.append(img)\n",
    "            return img\n",
    "        elif len(self.last_n_img) < self.n_frames :\n",
    "            self.last_n_img.append(img)\n",
    "        else:\n",
    "            self.last_n_img[:-1] = self.last_n_img[1:]\n",
    "            self.last_n_img[-1] = img\n",
    "        \n",
    "        ovl = np.zeros_like(img)\n",
    "        for i in range(len(self.last_n_img)):\n",
    "            ovl = ovl + self.last_n_img[i]\n",
    "        ovl[(ovl > 0)] = 1\n",
    "        return ovl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_coefs = np.array([[0,0,0]], dtype=np.float32)\n",
    "right_coefs = np.array([[0,0,0]], dtype=np.float32)\n",
    "\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "img_overlap = ImgOverlap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=9, thresh=(35, 255)):\n",
    "    #HLS = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    HLS=img\n",
    "    gray = HLS[:,:,0] # get R component\n",
    "    sobel = cv2.Sobel(gray, cv2.CV_64F, int(orient=='x'), int(orient=='y'), ksize=sobel_kernel)\n",
    "    sobel_abs = np.absolute(sobel)\n",
    "    sobel_scaled = 255 * sobel_abs/np.max(sobel_abs)\n",
    "    \n",
    "    grad_binary = np.zeros_like(sobel_scaled)\n",
    "    grad_binary[(sobel_scaled>thresh[0]) & (sobel_scaled<thresh[1])] = 1\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=9, thresh=(0, 255)):\n",
    "    HLS = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    gray = HLS[:,:,2] # get S component\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    sobel_mag = (sobelx**2 + sobely**2)**0.5\n",
    "    sobel_scaled = 255 * sobel_mag/np.max(sobel_mag)\n",
    "    \n",
    "    mag_binary = np.zeros_like(sobel_scaled)\n",
    "    mag_binary[(sobel_scaled>thresh[0]) & (sobel_scaled<thresh[1])] = 1\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=9, thresh=(0, np.pi/2)):\n",
    "    HLS = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    gray = HLS[:,:,2] # get S component\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    sobelx_abs = np.absolute(sobelx)\n",
    "    sobely_abs = np.absolute(sobely)\n",
    "    \n",
    "    sobel_dir = np.arctan2(sobely_abs, sobelx_abs)\n",
    "    \n",
    "    dir_binary = np.zeros_like(sobel_dir)\n",
    "    dir_binary[(sobel_dir>thresh[0]) & (sobel_dir<thresh[1])] = 1\n",
    "    return dir_binary\n",
    "\n",
    "def S_threshold(img, thresh=(90,255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    S = hls[:,:,2]\n",
    "    binary = np.zeros_like(S)\n",
    "    binary[(S>thresh[0]) & (S<=thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "def L_threshold(img, thresh=(90,255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    L = hls[:,:,1]\n",
    "    binary = np.zeros_like(L)\n",
    "    binary[(L>thresh[0]) & (L<=thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "def extract_thresh(img):\n",
    "    S = S_threshold(img, thresh=thresh_S)\n",
    "    L = L_threshold(img, thresh=thresh_L)\n",
    "    X = abs_sobel_thresh(img, thresh=thresh_x_grad)\n",
    "    \n",
    "    binary = np.zeros_like(S)\n",
    "    binary[(S>0) & (L>0) | (X>0)] = 1\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def apply_opening(img):\n",
    "    kernel = np.ones((1,3), np.uint8)\n",
    "    return cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "def undistort(img):\n",
    "    return cv2.undistort(img, camera_mtx, distortion, None, camera_mtx)\n",
    "\n",
    "def warp_image(img):\n",
    "    return cv2.warpPerspective(img, M, (shape_x, shape_y))\n",
    "\n",
    "def unwarp_image(img):\n",
    "    return cv2.warpPerspective(img, Minv, (shape_x, shape_y))\n",
    "\n",
    "def rescale(img, fx=fx, fy=fy):\n",
    "    return cv2.resize(img, (0,0), fx=0.1, fy=0.1)\n",
    "\n",
    "def top_k_labels(y, k=2):\n",
    "    uniq, count = np.unique(y, return_counts=True)\n",
    "    if np.argwhere(uniq==-1).size!=0:\n",
    "        count[np.argwhere(uniq==-1)]=0\n",
    "    seq = np.argsort(count)\n",
    "    top_k = []\n",
    "    try:\n",
    "        for i in range(k):\n",
    "            top_k.append(uniq[seq[-1*(i+1)]])\n",
    "        return np.array(top_k)\n",
    "    except (IndexError):\n",
    "        global invalid_centroids\n",
    "        invalid_centroids += 1\n",
    "        return None\n",
    "\n",
    "def get_pointsets(img):\n",
    "    dbscan = DBSCAN(eps=epsilon, min_samples=min_samples)\n",
    "    nonzeros = np.array(np.nonzero(img), dtype=np.float32).T\n",
    "    \n",
    "    y = dbscan.fit_predict(nonzeros)\n",
    "    \n",
    "    top_labels = top_k_labels(y)\n",
    "    \n",
    "    if top_labels == None:\n",
    "        return None\n",
    "    else:\n",
    "        return (nonzeros[y==top_labels[0]], nonzeros[y==top_labels[1]])\n",
    "\n",
    "def fit_lines(ploty, fit1, fit2, fx=0.1, fy=0.1):\n",
    "    left_fitx = (fit1[0]*(ploty*fy)**2 + fit1[1]*ploty*fy + fit1[2])/fx\n",
    "    right_fitx = (fit2[0]*(ploty*fy)**2 + fit2[1]*ploty*fy + fit2[2])/fx\n",
    "    \n",
    "    # Seperate left and right point sets\n",
    "    if np.average(left_fitx) < np.average(right_fitx):\n",
    "        return left_fitx, right_fitx\n",
    "    else:\n",
    "        return right_fitx, left_fitx\n",
    "\n",
    "def record_coefs(fit1, fit2, x1, x2):\n",
    "    if fit1[2] < fit2[2]:\n",
    "        fit_left = fit1\n",
    "        fit_right = fit2\n",
    "        left_fitx = x1\n",
    "        right_fitx = x2\n",
    "    else:\n",
    "        fit_left = fit2\n",
    "        fit_right = fit1\n",
    "        left_fitx = x2\n",
    "        right_fitx = x1\n",
    "    \n",
    "    global left_line, right_line\n",
    "    fit_left, left_fitx = left_line.validate(fit_left, left_fitx)\n",
    "    fit_right, right_fitx = right_line.validate(fit_right, right_fitx)\n",
    "    \n",
    "    return fit_left, fit_right, left_fitx, right_fitx\n",
    "\n",
    "def draw_unwarp(img, warped, ploty, left_fitx, right_fitx, warped_ovl=None):\n",
    "    # Create an image to draw the lines on - FROM Udacity class\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (shape_x, shape_y)) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    # Add the mini warped images as PIP on top-right of the returned image\n",
    "    if warped_ovl !=None :\n",
    "        pip = rescale(warped_ovl) * 255\n",
    "        pip = np.dstack((pip, pip, pip))\n",
    "        result[70:142, 1000:1128] = pip\n",
    "    \n",
    "    # Add text\n",
    "    text = \"radius = {:.3f}m\".format(left_line.radius_of_curvature)\n",
    "    text2 = \"offset = {:.3f}m\".format(get_offset(left_line, right_line))\n",
    "    result = cv2.putText(result, text, (10,60), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    result = cv2.putText(result, text2, (800,60), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_offset(leftline, rightline):\n",
    "    lane_width = np.min(rightline.avg_x) - np.min(leftline.avg_x)\n",
    "    offset = (shape_x/2 - np.min(leftline.avg_x)) - lane_width/2\n",
    "    \n",
    "    #in metres\n",
    "    offset = offset * leftline.mx\n",
    "    return offset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing pipeline ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img):\n",
    "    original = np.copy(img)\n",
    "    img = undistort(img)\n",
    "    img = extract_thresh(img)\n",
    "    \n",
    "    img = warp_image(img)\n",
    "    img = apply_opening(img)\n",
    "    \n",
    "    global img_overlap\n",
    "    img_ovl = img_overlap.overlap(img)\n",
    "    img_scaled = rescale(img_ovl)\n",
    "    \n",
    "    clusters = get_pointsets(img_scaled)\n",
    "    \n",
    "    if clusters == None:\n",
    "        fit1 = left_line.avg_fit\n",
    "        fit2 = right_line.avg_fit\n",
    "        # Get XY points\n",
    "        ploty = np.linspace(0, shape_y-1, shape_y )\n",
    "        left_fitx, right_fitx = fit_lines(ploty, fit1, fit2, fx=1, fy=1)\n",
    "    else:\n",
    "        fit1 = np.polyfit(clusters[0][:,0], clusters[0][:,1], 2) * [fy**2/fx, fy/fx, fx**-1 ]\n",
    "        fit2 = np.polyfit(clusters[1][:,0], clusters[1][:,1], 2) * [fy**2/fx, fy/fx, fx**-1 ]\n",
    "        \n",
    "        # Get XY points\n",
    "        ploty = np.linspace(0, shape_y-1, shape_y )\n",
    "        left_fitx, right_fitx = fit_lines(ploty, fit1, fit2, fx=1, fy=1)\n",
    "    \n",
    "    # Store coefs to plot later\n",
    "    fit1, fit2, left_fitx, right_fitx = record_coefs(fit1, fit2, left_fitx, right_fitx) \n",
    "    \n",
    "    result = draw_unwarp(original, img, ploty, left_fitx, right_fitx, warped_ovl=img_ovl)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply pipeline to Project Video (main) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [02:47<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "video1 = 'project_video.mp4'\n",
    "video1_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(video1)#.subclip(37,50)\n",
    "imgs = clip1.fl_image(process_img)\n",
    "%time imgs.write_videofile(video1_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
